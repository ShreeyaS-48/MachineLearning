{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":4834009,"datasetId":2801174,"databundleVersionId":4897791}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.690853Z","iopub.execute_input":"2026-02-20T09:46:44.691210Z","iopub.status.idle":"2026-02-20T09:46:44.701148Z","shell.execute_reply.started":"2026-02-20T09:46:44.691164Z","shell.execute_reply":"2026-02-20T09:46:44.700378Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/50startups/50_Startups_dataset.csv\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.702672Z","iopub.execute_input":"2026-02-20T09:46:44.702977Z","iopub.status.idle":"2026-02-20T09:46:44.712262Z","shell.execute_reply.started":"2026-02-20T09:46:44.702950Z","shell.execute_reply":"2026-02-20T09:46:44.711246Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/50startups/50_Startups_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.716504Z","iopub.execute_input":"2026-02-20T09:46:44.716845Z","iopub.status.idle":"2026-02-20T09:46:44.734279Z","shell.execute_reply.started":"2026-02-20T09:46:44.716810Z","shell.execute_reply":"2026-02-20T09:46:44.733206Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.735789Z","iopub.execute_input":"2026-02-20T09:46:44.736141Z","iopub.status.idle":"2026-02-20T09:46:44.743340Z","shell.execute_reply.started":"2026-02-20T09:46:44.736108Z","shell.execute_reply":"2026-02-20T09:46:44.742338Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"(50, 6)"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.744521Z","iopub.execute_input":"2026-02-20T09:46:44.744925Z","iopub.status.idle":"2026-02-20T09:46:44.764938Z","shell.execute_reply.started":"2026-02-20T09:46:44.744887Z","shell.execute_reply":"2026-02-20T09:46:44.764013Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50 entries, 0 to 49\nData columns (total 6 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Unnamed: 0       50 non-null     int64  \n 1   R&D Spend        50 non-null     float64\n 2   Administration   50 non-null     float64\n 3   Marketing Spend  50 non-null     float64\n 4   State            50 non-null     object \n 5   Profit           50 non-null     float64\ndtypes: float64(4), int64(1), object(1)\nmemory usage: 2.5+ KB\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.766063Z","iopub.execute_input":"2026-02-20T09:46:44.766464Z","iopub.status.idle":"2026-02-20T09:46:44.784994Z","shell.execute_reply.started":"2026-02-20T09:46:44.766438Z","shell.execute_reply":"2026-02-20T09:46:44.784110Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0         0\nR&D Spend          0\nAdministration     0\nMarketing Spend    0\nState              0\nProfit             0\ndtype: int64"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"df.drop(columns = ['Unnamed: 0'], inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.786905Z","iopub.execute_input":"2026-02-20T09:46:44.787177Z","iopub.status.idle":"2026-02-20T09:46:44.801741Z","shell.execute_reply.started":"2026-02-20T09:46:44.787152Z","shell.execute_reply":"2026-02-20T09:46:44.800613Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"X = df.iloc[:, :-1]\ny = df.iloc[:, -1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.803124Z","iopub.execute_input":"2026-02-20T09:46:44.803473Z","iopub.status.idle":"2026-02-20T09:46:44.819231Z","shell.execute_reply.started":"2026-02-20T09:46:44.803442Z","shell.execute_reply":"2026-02-20T09:46:44.818175Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.820413Z","iopub.execute_input":"2026-02-20T09:46:44.820690Z","iopub.status.idle":"2026-02-20T09:46:44.839854Z","shell.execute_reply.started":"2026-02-20T09:46:44.820665Z","shell.execute_reply":"2026-02-20T09:46:44.838774Z"}},"outputs":[],"execution_count":86},{"cell_type":"markdown","source":"# Gradient Boosting Regression From Scratch","metadata":{}},{"cell_type":"code","source":"def get_attribute_type(series):\n    if series.dtype == \"object\":\n        return \"discrete\"\n    if str(series.dtype).startswith((\"int\", \"float\")):\n        return \"continuous\"\n    return \"discrete\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.841512Z","iopub.execute_input":"2026-02-20T09:46:44.842008Z","iopub.status.idle":"2026-02-20T09:46:44.858839Z","shell.execute_reply.started":"2026-02-20T09:46:44.841958Z","shell.execute_reply":"2026-02-20T09:46:44.857673Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"class Node:\n    def __init__(self, \n                is_leaf = False, \n                label = None, \n                splitting_attribute = None, \n                splitting_attribute_value = None, \n                splitting_attribute_type = None,\n                depth = None,\n                mse = None):\n        self.is_leaf = is_leaf\n        self.splitting_attribute = splitting_attribute\n        self.splitting_attribute_value = splitting_attribute_value\n        self.label = label\n        self.children = {}\n        self.depth = depth\n        self.mse = mse\n        self.splitting_attribute_type = splitting_attribute_type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.860287Z","iopub.execute_input":"2026-02-20T09:46:44.860663Z","iopub.status.idle":"2026-02-20T09:46:44.882801Z","shell.execute_reply.started":"2026-02-20T09:46:44.860626Z","shell.execute_reply":"2026-02-20T09:46:44.881748Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"class DecisionTreeRegressor:\n    def __init__(self, max_depth = None, min_samples_leaf = 1, min_samples_split = 2, min_impurity_decrease = 0.0, max_features = None):\n        self.root = None\n        self.max_depth = max_depth\n        self.min_samples_leaf = min_samples_leaf\n        self.min_samples_split = min_samples_split\n        self.min_impurity_decrease = min_impurity_decrease\n        self.max_features = max_features\n\n    def calc_mse(self, y_train):\n        y = np.asarray(y_train)\n        if len(y) == 0:\n            return 0.0\n        mean = np.mean(y)\n        return np.mean((y - mean)**2)\n        \n    def calc_gain(self, X_train, y_train, attribute, min_samples_leaf):\n        mse = None\n        left_over_mse = 0.0\n        n = len(y_train)\n        if n == 0:\n            return (float('-inf'), None)\n        info_gain = float('-inf')\n        attribute_type = get_attribute_type(X_train[attribute])\n        attribute_value = None\n        mse = self.calc_mse(y_train)\n        if attribute_type == 'discrete':\n            values = X_train[attribute].dropna().unique()\n            if len(values) <= 1:\n                return (float('-inf'), None)\n            for av in values:\n                mask = X_train[attribute] == av\n                labels = y_train[mask]\n                if len(labels) < min_samples_leaf:\n                    return (float('-inf'), None)\n                ni = len(labels)\n                left_over_mse += (ni/n) * self.calc_mse(labels)\n            info_gain = mse - left_over_mse\n        else:\n            values = sorted(X_train[attribute].unique())\n            min_left_over_mse = mse\n            for i in range(len(values)-1):\n                av = (values[i] + values[i+1])/2\n                left = y_train[X_train[attribute]<=av]\n                right = y_train[X_train[attribute]>av]\n                if len(left) < min_samples_leaf or len(right) < min_samples_leaf:\n                    continue\n                    left_over_mse = (len(left)/n) * self.calc_mse(left) + (len(right)/n) * self.calc_mse(right)\n                if left_over_mse < min_left_over_mse:\n                    min_left_over_mse = left_over_mse\n                    attribute_value = av\n                    info_gain = mse - left_over_mse\n            if attribute_value is None:\n                return (float('-inf'), None)\n        return (info_gain, attribute_value)\n        \n    def build_tree(self, X_train, y_train, attributes, depth=0):\n        new_node = Node()\n        y = np.asarray(y_train)\n        value = np.mean(y)\n        new_node.label = value\n        if (self.max_depth is not None and depth == self.max_depth) or len(y_train) < self.min_samples_split:\n            new_node.is_leaf = True\n            return new_node\n        is_pure = True\n        label = y_train.iloc[0]\n        new_node.mse = self.calc_mse(y_train)\n        new_node.depth = depth\n        for curr_label in y_train:\n            if curr_label != label:\n                is_pure = False\n                break\n        if is_pure:\n            new_node.is_leaf = True\n            return new_node\n        gains = []\n        attributes_subset = attributes.copy()\n        if self.max_features == 'sqrt':\n            k = int(np.sqrt(len(attributes)))\n            attributes_subset = random.sample(attributes, k)\n        elif(self.max_features == 'log2'):\n            k = int(np.log2(len(attributes)))\n            attributes_subset = random.sample(attributes, k)\n        elif(type(self.max_features) == int):\n            attributes_subset = random.sample(attributes, self.max_features)\n        elif(type(self.max_features) == float):\n            attributes_subset = random.sample(attributes, int(self.max_features*len(attributes)))\n        for attribute in attributes_subset:\n            (gain_a, attribute_value) = self.calc_gain(X_train, y_train, attribute, self.min_samples_leaf)\n            gains.append((gain_a,(attribute, attribute_value)))\n        gains.sort(key=lambda x: x[0], reverse=True)\n        best_gain = gains[0][0]\n        if best_gain<self.min_impurity_decrease:\n            new_node.is_leaf = True\n            return new_node\n        splitting_attribute = gains[0][1][0]\n        splitting_attribute_value = gains[0][1][1]\n        new_node.splitting_attribute = splitting_attribute\n        new_node.splitting_attribute_value = splitting_attribute_value\n        splitting_attribute_type = get_attribute_type(X_train[splitting_attribute])\n        new_node.splitting_attribute_type = splitting_attribute_type\n        if splitting_attribute_type == 'discrete':   \n            for av in X_train[splitting_attribute].unique():\n                mask = X_train[splitting_attribute] == av\n                new_node.children[av] = self.build_tree(X_train[mask], y_train[mask], attributes,depth = depth +1)\n        else :\n            mask_left = X_train[splitting_attribute] < splitting_attribute_value\n            mask_right = X_train[splitting_attribute] >= splitting_attribute_value\n            new_node.children[\"<=\"] = self.build_tree(X_train[mask_left], y_train[mask_left], attributes, depth = depth+1)\n            new_node.children[\">\"] = self.build_tree(X_train[mask_right], y_train[mask_right], attributes, depth = depth+1)\n        return new_node\n        \n    def fit(self, X_train, y_train):\n        self.root = self.build_tree(X_train, y_train, list(X_train.columns))\n\n    def print_paths(self, root, path):\n        if root is None:\n            return\n        if root.is_leaf:\n            for s in path:\n                print(s, end = \" \")\n            print(\"=> \", root.label)\n            return\n        for value, child in root.children.items():\n            if root.splitting_attribute_type == 'discrete':\n                path.append(f\"{root.splitting_attribute} (mse = {round(root.mse,3)}) ={value}\")\n            else:\n                path.append(f\"{root.splitting_attribute} (mse = {round(root.mse,3)}) {value} {root.splitting_attribute_value}\")\n            self.print_paths(child, path)\n            path.pop()\n            \n    def print_tree(self):\n        self.print_paths(self.root, [])\n    def predict(self, X_test):\n        y_pred = []\n        for i in range(len(X_test)):\n            curr = self.root\n            while curr and not curr.is_leaf:\n                attr = curr.splitting_attribute\n                val = X_test.iloc[i][attr]\n                if hasattr(val, \"item\"):\n                    val = val.item()\n                if curr.splitting_attribute_type == 'discrete':\n                    if val in curr.children:\n                        curr = curr.children[val]\n                    else:\n                        break   \n                else:\n                    if val <= curr.splitting_attribute_value:\n                        curr = curr.children[\"<=\"]\n                    else:\n                        curr = curr.children[\">\"]\n            y_pred.append(curr.label)\n        return y_pred\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.884789Z","iopub.execute_input":"2026-02-20T09:46:44.885088Z","iopub.status.idle":"2026-02-20T09:46:44.913580Z","shell.execute_reply.started":"2026-02-20T09:46:44.885062Z","shell.execute_reply":"2026-02-20T09:46:44.912319Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"class GradientBoostingRegressor:\n    def __init__(self, learning_rate = 1.0, max_depth = 3, min_samples_leaf = 1, min_samples_split = 2, min_impurity_decrease = 0.0, max_features = None, n_estimators = 100, subsample = 1.0):\n        self.max_depth = max_depth\n        self.min_samples_leaf = min_samples_leaf\n        self.min_samples_split = min_samples_split\n        self.min_impurity_decrease = min_impurity_decrease\n        self.max_features = max_features\n        self.n_estimators = n_estimators\n        self.subsample = subsample\n        self.estimators = []\n        self.initial_prediction = None\n        self.learning_rate = learning_rate\n\n    def fit(self, X_train, y_train):\n        n = X_train.shape[0]\n        self.initial_prediction = np.mean(y_train)\n        y_pred = np.full_like(y_train, self.initial_prediction, dtype=float)\n        for i in range(self.n_estimators):\n            residuals = y_train - y_pred\n            if self.subsample < 1.0:\n                size = int(self.subsample * n)\n                idx = np.random.choice(n, size=size, replace=False)\n                X_sub = X_train.iloc[idx].reset_index(drop=True)\n                residuals_sub = residuals.iloc[idx].reset_index(drop=True)\n            else:\n                X_sub = X_train\n                residuals_sub = residuals\n            clf = DecisionTreeRegressor(max_depth = self.max_depth, min_samples_leaf = self.min_samples_leaf, min_samples_split = self.min_samples_split, max_features = self.max_features, min_impurity_decrease = self.min_impurity_decrease)\n            clf.fit(X_sub, residuals_sub)\n            update = np.array(clf.predict(X_train))\n            y_pred = y_pred + self.learning_rate * update\n            self.estimators.append(clf)\n    def predict(self, X_test):\n        y_pred = np.full(X_test.shape[0], self.initial_prediction)\n        for clf in self.estimators:\n            y_pred += self.learning_rate * np.array(clf.predict(X_test))\n        return y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.915511Z","iopub.execute_input":"2026-02-20T09:46:44.915918Z","iopub.status.idle":"2026-02-20T09:46:44.932124Z","shell.execute_reply.started":"2026-02-20T09:46:44.915889Z","shell.execute_reply":"2026-02-20T09:46:44.931154Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"gb = GradientBoostingRegressor(n_estimators = 200, subsample = 0.4, min_samples_leaf = 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.933405Z","iopub.execute_input":"2026-02-20T09:46:44.933760Z","iopub.status.idle":"2026-02-20T09:46:44.952884Z","shell.execute_reply.started":"2026-02-20T09:46:44.933720Z","shell.execute_reply":"2026-02-20T09:46:44.951592Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"gb.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:44.954843Z","iopub.execute_input":"2026-02-20T09:46:44.955276Z","iopub.status.idle":"2026-02-20T09:46:54.759685Z","shell.execute_reply.started":"2026-02-20T09:46:44.955238Z","shell.execute_reply":"2026-02-20T09:46:54.758664Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"y_pred = gb.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:54.760781Z","iopub.execute_input":"2026-02-20T09:46:54.761104Z","iopub.status.idle":"2026-02-20T09:46:54.841013Z","shell.execute_reply.started":"2026-02-20T09:46:54.761078Z","shell.execute_reply":"2026-02-20T09:46:54.840005Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T09:46:54.842115Z","iopub.execute_input":"2026-02-20T09:46:54.842502Z","iopub.status.idle":"2026-02-20T09:46:54.850526Z","shell.execute_reply.started":"2026-02-20T09:46:54.842475Z","shell.execute_reply":"2026-02-20T09:46:54.849593Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"0.6615882098754442"},"metadata":{}}],"execution_count":94}]}